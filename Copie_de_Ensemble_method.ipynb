{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copie de Ensemble method.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzZAb6cZPZb+EtbXMfRLcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Letsgetloud/Test/blob/main/Copie_de_Ensemble_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nknCkGvGunbc"
      },
      "source": [
        "Ensemble method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELH7ZNnnumNF"
      },
      "source": [
        "We train a meta-learner that will best combine the predictions from the different models and ideally perform better than any single sub-model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXQUq0MMvs_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d61b1a5-49bc-4a20-d630-d19f53e38cfe"
      },
      "source": [
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from skimage import io\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import StratifiedKFold , cross_val_score , cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from numpy import dstack\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib #to load and save sklearn models\n",
        "\n",
        "GDRIVE_MOUNT_POINT = '/content/drive'\n",
        "WORK_DIR = \"/content/drive/MyDrive/work/Oliv\"\n",
        "MODEL_DIR = \"/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/\"\n",
        "\n",
        "if not os.path.isdir(GDRIVE_MOUNT_POINT):\n",
        "  drive.mount(GDRIVE_MOUNT_POINT)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWXG3bPNxqm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1831d9ab-bb9a-4b62-f584-470516906a43"
      },
      "source": [
        "#list all h5 models in a main directory\n",
        "def listdirectory2(path): \n",
        "    fichier=[] \n",
        "    for root, dirs, files in os.walk(path): \n",
        "        if (\"0002/train/0001\" in root):\n",
        "            for i in files:\n",
        "                full_name= os.path.join(root, i)\n",
        "                root, extension = os.path.splitext(full_name)\n",
        "                if extension==\".h5\": fichier.append(full_name) \n",
        "    return fichier\n",
        "\n",
        "listdirectory2(MODEL_DIR)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb0/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb1/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb2/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb3/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb4/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb5/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb6/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb7/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/xception/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/vgg16/0002/train/0001/model/best_model.h5',\n",
              " '/content/drive/MyDrive/work/dad/output/classifier/multiclass/10/vgg19/0002/train/0001/model/best_model.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9077EnfO6j8o",
        "outputId": "c491e352-9d0b-448a-cc37-600fb5edecff"
      },
      "source": [
        "#Prepare the image test set for model evaluation\n",
        "\n",
        "df_genus = pd.read_csv( \\\n",
        "      filepath_or_buffer = WORK_DIR + '/' + \"df_genus_2k_clean.csv\"\n",
        "   ,  sep = ','\n",
        "   ,  header = 0\n",
        ")\n",
        "\n",
        "filtre_genus=df_genus.taxon_name.value_counts().index[:10]\n",
        "print(filtre_genus)\n",
        "t= df_genus.shape\n",
        "df_genus=df_genus[df_genus[\"taxon_name\"].isin(filtre_genus)].reset_index()\n",
        "\n",
        "#Prepare train and test sets\n",
        "X= df_genus[df_genus[\"taxon_name\"].isin(filtre_genus)][[\"img_path\",\"taxon_name\"]]\n",
        "\n",
        "#split the dataset between 80% train, 20% validation and 10% test)\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=1)\n",
        "X_train, X_val= train_test_split(X_train, test_size=0.125, random_state=1)\n",
        "\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, stratify = X[\"taxon_name\"], random_state=88)\n",
        "X_train, X_val= train_test_split(X_train, test_size=0.125,stratify = X_train[\"taxon_name\"], random_state=43)\n",
        "\n",
        "\n",
        "print(\"shape : \", t)\n",
        "print(\"shape X genus: \", X.shape)\n",
        "print(\"shape train: \", X_train.shape)\n",
        "print(\"shape test:\", X_test.shape)\n",
        "print(\"shape valid: \", X_val.shape)\n",
        "\n",
        "X_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "list_genus= np.sort(np.array(X_val.taxon_name.value_counts().index))\n",
        "y_val = []\n",
        "for elem in list(X_val.taxon_name):\n",
        "    y_val.append(np.argwhere(list_genus == elem)[0][0])\n",
        "\n",
        "X_train_sclf, X_test_sclf, y_train_sclf, y_test_sclf = train_test_split(X_val, y_val, test_size=0.2, stratify = X_val[\"taxon_name\"], random_state=1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Amanita', 'Hygrocybe', 'Armillaria', 'Lactarius', 'Agaricus',\n",
            "       'Gymnopus', 'Cortinarius', 'Russula', 'Marasmius', 'Entoloma'],\n",
            "      dtype='object')\n",
            "shape :  (27080, 39)\n",
            "shape X genus:  (18560, 2)\n",
            "shape train:  (12992, 2)\n",
            "shape test: (3712, 2)\n",
            "shape valid:  (1856, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hUTNjZEsus_I",
        "outputId": "15332312-6d10-4f4d-ef00-2a12cc730224"
      },
      "source": [
        "#STACKING MODEL CALIBRATION\n",
        "\n",
        "#load models from file\n",
        "def load_all_models():\n",
        "    all_models = {}\n",
        "    filenames = []\n",
        "    for root, dirs, files in os.walk(MODEL_DIR): \n",
        "        if (\"0002/train/0001\" in root):\n",
        "            for i in files:\n",
        "                full_name= os.path.join(root, i)\n",
        "                root, extension = os.path.splitext(full_name)\n",
        "                if extension==\".h5\": filenames.append(full_name) \n",
        "    for file in filenames:\n",
        "        if \"xception\" not in file:\n",
        "            model = tf.keras.models.load_model(file)\n",
        "            name = file.replace(MODEL_DIR, \"\")\n",
        "            name = name.replace(\"/0002/train/0001/model/best_model.h5\" , \"\")\n",
        "            # add to list of members\n",
        "            all_models[name]=model\n",
        "            print('>Loading model %s' % file)\n",
        "    return all_models\n",
        "\n",
        "\n",
        "# load all models   \n",
        "members = load_all_models()\n",
        "print('Loaded %d models' % len(members))\n",
        "\n",
        "stackX_train = None\n",
        "stackX_test = None\n",
        "results={}\n",
        "\n",
        "for name, model in members.items():\n",
        "    print(\"\\n Analyzing \", name)\n",
        "    IMG_SIZE= model.input.get_shape().as_list()[1:3]\n",
        "    if \"efficientnet\" in name:\n",
        "        preprocess_input = None\n",
        "    elif \"vgg16\" in name:\n",
        "        preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
        "    elif \"vgg19\" in name:\n",
        "        preprocess_input = tf.keras.applications.vgg19.preprocess_input\n",
        "    elif \"xception\" in name:\n",
        "        preprocess_input = tf.keras.applications.xception.preprocess_input\n",
        "    else :\n",
        "        raise NameError('No preprocess input specified') \n",
        "#else + exception \n",
        "\n",
        "    datagen= tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "    train_generator= datagen.flow_from_dataframe(dataframe=X_train_sclf, directory=\"\",\n",
        "                                            x_col=\"img_path\", y_col=\"taxon_name\", shuffle=False,\n",
        "                                            class_mode=\"sparse\", target_size=IMG_SIZE, batch_size=32)\n",
        "    test_generator= datagen.flow_from_dataframe(dataframe=X_test_sclf, directory=\"\",\n",
        "                                            x_col=\"img_path\", y_col=\"taxon_name\", shuffle=False,\n",
        "                                            class_mode=\"sparse\", target_size=IMG_SIZE, batch_size=32)\n",
        "    # evaluate standalone models on test dataset\n",
        "    metrics = model.evaluate(train_generator)  #renvoi plusieurs scalars selon le nb de métrique choisies : loss, accuracy,..\n",
        "    results[name] = metrics\n",
        "    print('Model Accuracy: %.3f' % metrics[1])\n",
        "\n",
        "    # make prediction\n",
        "    print(\"Making predictions for \" , name)\n",
        "    y_train_pred = model.predict(train_generator, verbose=0)\n",
        "    y_test_pred = model.predict(test_generator, verbose=0)\n",
        "    # stack predictions into [rows, members, probabilities]\n",
        "    if stackX_train is None:\n",
        "        stackX_train = y_train_pred\n",
        "    else:\n",
        "        stackX_train = dstack((stackX_train, y_train_pred))\n",
        "    if stackX_test is None:\n",
        "        stackX_test = y_test_pred\n",
        "    else:\n",
        "        stackX_test = dstack((stackX_test, y_test_pred))\n",
        "\n",
        "    del model\n",
        "\n",
        "# flatten predictions to [rows, members x probabilities]\n",
        "stackX_train = stackX_train.reshape((stackX_train.shape[0], stackX_train.shape[1]*stackX_train.shape[2]))\n",
        "stackX_test = stackX_test.reshape((stackX_test.shape[0], stackX_test.shape[1]*stackX_test.shape[2]))\n",
        "\n",
        "\n",
        "#try Logistic Regression\n",
        "model_lr = LogisticRegression()\n",
        "cv = StratifiedKFold(n_splits= 3, shuffle=True)\n",
        "scores = cross_val_score(model_lr, stackX_train, y_train_sclf, cv = cv)\n",
        "print(\"\\n > Log Reg Accuracy mean \" , '{:,.1%}'.format(np.mean(scores)), \" std dev \",'{:,.1%}'.format(np.std(scores)))\n",
        "#y_pred_lr = cross_val_predict(model_lr, stackX, val_generator.classes , cv=cv )\n",
        "#print(\"\\n\", classification_report(val_generator.classes, y_pred_lr, target_names=list_genus))\n",
        "#df_cm=pd.DataFrame(confusion_matrix(y_pred_lr,val_generator.classes))\n",
        "#plt.figure(figsize = (10,5))\n",
        "#sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "#print('\\n\\n>>>>>> Stacked Test Accuracy with LogReg model: %.3f' % acc)\n",
        "\n",
        "#Try SVM\n",
        "model_svm = SVC(probability=True)\n",
        "scores = cross_val_score(model_svm, stackX_train, y_train_sclf, cv = cv)\n",
        "print(\"\\n > SVM Accuracy mean \" , '{:,.1%}'.format(np.mean(scores)), \" std dev \",'{:,.1%}'.format(np.std(scores)))\n",
        "#y_pred_svm = cross_val_predict(model_svm, stackX, val_generator.classes , cv=cv )\n",
        "#print(\"\\n\", classification_report(val_generator.classes, y_pred_svm, target_names=list_genus))\n",
        "#df_cm=pd.DataFrame(confusion_matrix(y_pred_svm,val_generator.classes))\n",
        "#plt.figure(figsize = (10,5))\n",
        "#sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "#try decision tree\n",
        "model_dtc = DecisionTreeClassifier()\n",
        "scores = cross_val_score(model_dtc, stackX_train, y_train_sclf, cv = cv)\n",
        "print(\"\\n > Tree Accuracy mean \" , '{:,.1%}'.format(np.mean(scores)), \" std dev \",'{:,.1%}'.format(np.std(scores)))\n",
        "#y_pred_dtc = cross_val_predict(model_dtc, stackX, val_generator.classes , cv=cv )\n",
        "#print(\"\\n\", classification_report(val_generator.classes, y_pred_dtc, target_names=list_genus))\n",
        "\n",
        "#le meta-learner permet d'atteindre 87% d'accuracy dépassant tous les autres "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb0/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb1/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb2/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb3/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb4/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb5/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb6/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/efficientnetb7/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/vgg16/0002/train/0001/model/best_model.h5\n",
            ">Loading model /content/drive/MyDrive/work/dad/output/classifier/multiclass/10/vgg19/0002/train/0001/model/best_model.h5\n",
            "Loaded 10 models\n",
            "\n",
            " Analyzing  efficientnetb0\n",
            "Found 1484 validated image filenames belonging to 10 classes.\n",
            "Found 372 validated image filenames belonging to 10 classes.\n",
            "47/47 [==============================] - 1005s 21s/step - loss: 0.8827 - accuracy: 0.6988 - top_2_accuracy: 0.8470 - top_5_accuracy: 0.9677\n",
            "Model Accuracy: 0.699\n",
            "Making predictions for  efficientnetb0\n",
            "\n",
            " Analyzing  efficientnetb1\n",
            "Found 1484 validated image filenames belonging to 10 classes.\n",
            "Found 372 validated image filenames belonging to 10 classes.\n",
            "47/47 [==============================] - 42s 832ms/step - loss: 0.9652 - accuracy: 0.6617 - top_2_accuracy: 0.8282 - top_5_accuracy: 0.9616\n",
            "Model Accuracy: 0.662\n",
            "Making predictions for  efficientnetb1\n",
            "\n",
            " Analyzing  efficientnetb2\n",
            "Found 1484 validated image filenames belonging to 10 classes.\n",
            "Found 372 validated image filenames belonging to 10 classes.\n",
            "47/47 [==============================] - 18s 305ms/step - loss: 0.9627 - accuracy: 0.6530 - top_2_accuracy: 0.8201 - top_5_accuracy: 0.9677\n",
            "Model Accuracy: 0.653\n",
            "Making predictions for  efficientnetb2\n",
            "\n",
            " Analyzing  efficientnetb3\n",
            "Found 1484 validated image filenames belonging to 10 classes.\n",
            "Found 372 validated image filenames belonging to 10 classes.\n",
            "47/47 [==============================] - 62s 1s/step - loss: 0.9309 - accuracy: 0.6712 - top_2_accuracy: 0.8349 - top_5_accuracy: 0.9697\n",
            "Model Accuracy: 0.671\n",
            "Making predictions for  efficientnetb3\n",
            "\n",
            " Analyzing  efficientnetb4\n",
            "Found 1484 validated image filenames belonging to 10 classes.\n",
            "Found 372 validated image filenames belonging to 10 classes.\n",
            "47/47 [==============================] - 80s 2s/step - loss: 0.7628 - accuracy: 0.7311 - top_2_accuracy: 0.8861 - top_5_accuracy: 0.9838\n",
            "Model Accuracy: 0.731\n",
            "Making predictions for  efficientnetb4\n",
            "\n",
            " Analyzing  efficientnetb5\n",
            "Found 1484 validated image filenames belonging to 10 classes.\n",
            "Found 372 validated image filenames belonging to 10 classes.\n",
            "47/47 [==============================] - 109s 2s/step - loss: 0.6608 - accuracy: 0.7736 - top_2_accuracy: 0.9090 - top_5_accuracy: 0.9818\n",
            "Model Accuracy: 0.774\n",
            "Making predictions for  efficientnetb5\n",
            "\n",
            " Analyzing  efficientnetb6\n",
            "Found 1484 validated image filenames belonging to 10 classes.\n",
            "Found 372 validated image filenames belonging to 10 classes.\n",
            "47/47 [==============================] - 42s 750ms/step - loss: 1.1488 - accuracy: 0.6018 - top_2_accuracy: 0.7682 - top_5_accuracy: 0.9434\n",
            "Model Accuracy: 0.602\n",
            "Making predictions for  efficientnetb6\n",
            "\n",
            " Analyzing  efficientnetb7\n",
            "Found 1484 validated image filenames belonging to 10 classes.\n",
            "Found 372 validated image filenames belonging to 10 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cc88538c5c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m                                             class_mode=\"sparse\", target_size=IMG_SIZE, batch_size=32)\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# evaluate standalone models on test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#renvoi plusieurs scalars selon le nb de métrique choisies : loss, accuracy,..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    955\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 957\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,192,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/block2a_expand_bn/FusedBatchNormV3 (defined at <ipython-input-3-cc88538c5c8c>:55) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_121772]\n\nFunction call stack:\ntest_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3-rfjpM84uI",
        "outputId": "16aba237-0568-4db9-eebe-0a84e331be1c"
      },
      "source": [
        "#META LEARNER CALIBRATION \n",
        "\n",
        "#fitting and predicting\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "dtc_clf = DecisionTreeClassifier()\n",
        "lr_clf = LogisticRegression(max_iter=1000)\n",
        "svm_clf = SVC()\n",
        "\n",
        "knn_params = {\"n_neighbors\":[2,5,7,9]}\n",
        "dtc_params = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
        "svm_params = {\"C\" : np.logspace(-3,3,7)}\n",
        "lr_params =  {\"C\" : np.logspace(-3,3,7)}\n",
        "\n",
        "knn_clf = GridSearchCV(knn_clf, param_grid = knn_params , cv=5)\n",
        "dtc_clf = GridSearchCV(dtc_clf, param_grid = dtc_params , cv=5)\n",
        "svm_clf = GridSearchCV(svm_clf, param_grid = svm_params , cv=5)\n",
        "lr_clf  = GridSearchCV(lr_clf, param_grid = lr_params , cv=5)\n",
        "\n",
        "knn_clf.fit(stackX_train, y_train_sclf)\n",
        "dtc_clf.fit(stackX_train, y_train_sclf)\n",
        "svm_clf.fit(stackX_train, y_train_sclf)\n",
        "lr_clf.fit(stackX_train, y_train_sclf)\n",
        "\n",
        "y_pred_test_knn = knn_clf.best_estimator_.predict(stackX_test)\n",
        "y_pred_test_dtc = dtc_clf.best_estimator_.predict(stackX_test)\n",
        "y_pred_test_svm = svm_clf.best_estimator_.predict(stackX_test)\n",
        "y_pred_test_lr = lr_clf.best_estimator_.predict(stackX_test)\n",
        "\n",
        "print(\"\\nKNN accuracy score on train : \", '{:,.1%}'.format(knn_clf.score(stackX_train, y_train_sclf)))\n",
        "print(\"KNN accuracy score on test : \", '{:,.1%}'.format(knn_clf.score(stackX_test, y_test_sclf)))\n",
        "print(\"\\nTREE accuracy score on train : \", '{:,.1%}'.format(dtc_clf.score(stackX_train, y_train_sclf)))\n",
        "print(\"TREE accuracy score on test : \", '{:,.1%}'.format(dtc_clf.score(stackX_test, y_test_sclf)))\n",
        "print(\"\\nSVM accuracy score on train : \", '{:,.1%}'.format(svm_clf.score(stackX_train, y_train_sclf)))\n",
        "print(\"SVM accuracy score on test : \", '{:,.1%}'.format(svm_clf.score(stackX_test, y_test_sclf)))\n",
        "print(\"\\nLogReg accuracy score on train : \", '{:,.1%}'.format(lr_clf.score(stackX_train, y_train_sclf)))\n",
        "print(\"LogReg accuracy score on test : \", '{:,.1%}'.format(lr_clf.score(stackX_test, y_test_sclf)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KNN accuracy score on train :  84.4%\n",
            "KNN accuracy score on test :  81.2%\n",
            "\n",
            "TREE accuracy score on train :  89.3%\n",
            "TREE accuracy score on test :  73.9%\n",
            "\n",
            "SVM accuracy score on train :  90.9%\n",
            "SVM accuracy score on test :  83.9%\n",
            "\n",
            "LogReg accuracy score on train :  85.3%\n",
            "LogReg accuracy score on test :  84.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "IJ8isrlkREOw",
        "outputId": "780e644e-26a7-4b14-f79a-2d4d457426d5"
      },
      "source": [
        "print(\"\\n\", classification_report(y_test_sclf, y_pred_test_lr, target_names=list_genus))\n",
        "df_cm=pd.DataFrame(metrics.confusion_matrix(y_test_sclf, y_pred_test_lr))\n",
        "plt.figure(figsize = (10,5))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Agaricus       0.88      0.97      0.93        38\n",
            "     Amanita       0.88      0.95      0.91        39\n",
            "  Armillaria       0.79      0.79      0.79        38\n",
            " Cortinarius       0.94      0.81      0.87        37\n",
            "    Entoloma       0.88      0.86      0.87        35\n",
            "    Gymnopus       0.68      0.92      0.78        37\n",
            "   Hygrocybe       0.97      0.82      0.89        38\n",
            "   Lactarius       0.86      0.63      0.73        38\n",
            "   Marasmius       0.89      0.86      0.87        36\n",
            "     Russula       0.79      0.86      0.83        36\n",
            "\n",
            "    accuracy                           0.85       372\n",
            "   macro avg       0.86      0.85      0.85       372\n",
            "weighted avg       0.86      0.85      0.85       372\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa16da3d950>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Ndo2Pqid92KN",
        "outputId": "192e0f83-b939-48ab-f84f-cd468c41c0e3"
      },
      "source": [
        "#Show accuracy on validation set for each of the individual CNN to be combined\n",
        "\n",
        "pd.DataFrame(results, index=[\"Loss\",\"Accuracy\",\"Top2_Accuracy\", \"Top5_Accuracy\"]).T.drop(\"Loss\", axis=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Top2_Accuracy</th>\n",
              "      <th>Top5_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>efficientnetb0</th>\n",
              "      <td>0.780323</td>\n",
              "      <td>0.896900</td>\n",
              "      <td>0.985175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>efficientnetb1</th>\n",
              "      <td>0.739218</td>\n",
              "      <td>0.887466</td>\n",
              "      <td>0.975741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>efficientnetb2</th>\n",
              "      <td>0.704178</td>\n",
              "      <td>0.848383</td>\n",
              "      <td>0.977763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>efficientnetb3</th>\n",
              "      <td>0.717655</td>\n",
              "      <td>0.870620</td>\n",
              "      <td>0.979784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>efficientnetb4</th>\n",
              "      <td>0.778302</td>\n",
              "      <td>0.901617</td>\n",
              "      <td>0.983154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>efficientnetb5</th>\n",
              "      <td>0.831536</td>\n",
              "      <td>0.935984</td>\n",
              "      <td>0.987871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>efficientnetb6</th>\n",
              "      <td>0.646226</td>\n",
              "      <td>0.801213</td>\n",
              "      <td>0.962264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>efficientnetb7</th>\n",
              "      <td>0.676550</td>\n",
              "      <td>0.850404</td>\n",
              "      <td>0.973720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vgg16</th>\n",
              "      <td>0.465633</td>\n",
              "      <td>0.659030</td>\n",
              "      <td>0.896900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vgg19</th>\n",
              "      <td>0.451482</td>\n",
              "      <td>0.629380</td>\n",
              "      <td>0.886792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Accuracy  Top2_Accuracy  Top5_Accuracy\n",
              "efficientnetb0  0.780323       0.896900       0.985175\n",
              "efficientnetb1  0.739218       0.887466       0.975741\n",
              "efficientnetb2  0.704178       0.848383       0.977763\n",
              "efficientnetb3  0.717655       0.870620       0.979784\n",
              "efficientnetb4  0.778302       0.901617       0.983154\n",
              "efficientnetb5  0.831536       0.935984       0.987871\n",
              "efficientnetb6  0.646226       0.801213       0.962264\n",
              "efficientnetb7  0.676550       0.850404       0.973720\n",
              "vgg16           0.465633       0.659030       0.896900\n",
              "vgg19           0.451482       0.629380       0.886792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ogyDxjYIkS1"
      },
      "source": [
        "#Finally save meta learner\n",
        "\n",
        "filename = 'ensemble_model.sav'\n",
        "joblib.dump(lr_clf, WORK_DIR +\"/saved_model/\"+ filename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}